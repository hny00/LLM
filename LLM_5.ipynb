{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGycUyhB/r6DAFwTt+rR9G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hny00/LLM/blob/main/LLM_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텍스트 정보검색\n",
        "\n",
        "**텍스트 정보 검색**(Text Information Retrieval, Text IR)은 대량의 텍스트 데이터에서 사용자가 입력한 질의(Query)와 관련된 문서나 정보를 찾아내는 과정을 의미합니다. 이는 검색 엔진, 문서 관리 시스템, 데이터베이스 등의 다양한 시스템에서 중요한 역할을 하며, 검색어를 입력하면 이에 맞는 문서나 텍스트를 효율적으로 찾아내는 것이 목적입니다.\n",
        "\n",
        "### 텍스트 정보 검색의 핵심 개념:\n",
        "\n",
        "1. **문서(Document)**: 텍스트로 이루어진 정보의 단위입니다. 예를 들어, 뉴스 기사, 블로그 글, 위키피디아 항목, 책의 챕터 등이 문서로 취급될 수 있습니다.\n",
        "2. **용어(Term)**: 문서나 질의에서 사용하는 단어 또는 어구를 의미합니다. 검색 시 사용자가 입력하는 키워드도 용어에 해당합니다.\n",
        "3. **역파일(Inverted Index)**: 텍스트 정보 검색에서 가장 중요한 자료 구조 중 하나로, 문서의 용어와 그 용어가 등장하는 문서들의 리스트를 효율적으로 저장하는 방식입니다. 이를 통해 특정 용어가 포함된 문서를 빠르게 찾을 수 있습니다.\n",
        "4. **질의(Query)**: 사용자가 검색하고자 입력하는 질문이나 키워드입니다. 텍스트 정보 검색 시스템은 이 질의를 바탕으로 가장 관련성이 높은 문서를 반환합니다.\n",
        "5. **관련성(Relevance)**: 검색 결과가 사용자 질의와 얼마나 관련이 있는지를 나타내는 개념입니다. 정보 검색 시스템은 검색된 문서들을 관련성 순으로 정렬하여 사용자에게 반환합니다.\n",
        "\n",
        "### 텍스트 정보 검색의 주요 단계:\n",
        "\n",
        "1. **텍스트 전처리 (Text Preprocessing)**:\n",
        "    - **토큰화 (Tokenization)**: 문서를 개별 단어 또는 구(phrase)로 분리하는 과정입니다.\n",
        "    - **정규화 (Normalization)**: 대소문자 통합, 불필요한 특수 문자 제거, 문법적 변형 처리 등을 통해 단어를 표준 형태로 변환합니다.\n",
        "    - **불용어 제거 (Stopword Removal)**: \"그리고\", \"또한\", \"있다\"와 같이 검색에 큰 영향을 미치지 않는 일반적인 단어들을 제거합니다.\n",
        "    - **어간 추출 (Stemming) 및 표제어 추출 (Lemmatization)**: 단어의 다양한 형태를 하나의 기본 형태로 통합하는 과정입니다. 예를 들어, \"먹는다\", \"먹고\", \"먹은\"을 모두 \"먹다\"로 변환합니다.\n",
        "2. **인덱싱 (Indexing)**:\n",
        "문서를 검색하기 위해 텍스트를 인덱스화하는 단계입니다. 인덱스는 일반적으로 역파일(Inverted Index)을 사용하여 각 용어가 등장하는 문서를 기록합니다. 이 자료 구조 덕분에 특정 용어가 포함된 문서를 빠르게 찾을 수 있습니다.\n",
        "3. **질의 처리 및 검색 (Query Processing & Searching)**:\n",
        "사용자가 입력한 질의를 처리하고 관련 문서를 검색하는 단계입니다. 이 과정에서는 검색어와 문서 내의 용어 간 유사성을 계산하여 가장 관련성이 높은 문서를 반환합니다.\n",
        "4. **랭킹 (Ranking)**:\n",
        "검색된 문서들이 사용자 질의와 얼마나 관련성이 있는지를 기준으로 정렬됩니다. 관련성을 계산하기 위해 다양한 방법이 사용됩니다.\n",
        "\n",
        "### 정보 검색의 주요 기법:\n",
        "\n",
        "1. **TF-IDF (Term Frequency-Inverse Document Frequency)**:\n",
        "    - **TF (Term Frequency)**: 특정 문서에서 특정 단어가 얼마나 자주 등장하는지를 나타내는 값입니다. 자주 등장하는 단어일수록 그 문서에서 중요한 단어로 간주됩니다.\n",
        "    - **IDF (Inverse Document Frequency)**: 특정 단어가 전체 문서에서 얼마나 흔한지를 나타내는 값입니다. 흔한 단어일수록 덜 중요한 단어로 간주됩니다.\n",
        "    - TF-IDF는 특정 단어가 해당 문서에서 얼마나 중요한지 계산하는 데 사용됩니다. 이 값을 통해 검색어와 문서 간의 유사도를 측정합니다.\n",
        "2. **벡터 공간 모델 (Vector Space Model, VSM)**:\n",
        "문서와 질의를 벡터로 표현하고, 코사인 유사도(Cosine Similarity) 같은 방법을 이용해 유사도를 계산하여 문서를 랭킹하는 방식입니다. 질의와 문서 간의 벡터가 얼마나 가까운지를 계산해 검색 결과를 정렬합니다.\n",
        "3. **BM25 (Best Matching 25)**:\n",
        "TF-IDF의 발전된 형태로, 문서 길이에 대한 가중치를 포함하여 검색어와 문서 간의 관련성을 계산하는 모델입니다. 현재 정보 검색 시스템에서 많이 사용되는 방법입니다.\n",
        "4. **랭킹 학습 (Learning to Rank)**:\n",
        "기계 학습을 사용해 검색 결과의 순위를 예측하는 방법입니다. 이 방법은 사용자의 피드백을 학습에 반영하여 관련성이 높은 문서를 우선적으로 반환하는 시스템을 구축할 수 있습니다.\n",
        "\n",
        "### 텍스트 정보 검색의 응용:\n",
        "\n",
        "- **검색 엔진**: 구글, 네이버와 같은 검색 엔진은 웹상의 방대한 데이터를 텍스트 정보 검색 기술을 사용해 검색하고 관련 결과를 반환합니다.\n",
        "- **문서 관리 시스템**: 회사 내에서 많은 문서나 파일을 관리하고, 필요할 때 빠르게 검색해내기 위해 텍스트 정보 검색 기술이 활용됩니다.\n",
        "- **추천 시스템**: 사용자가 관심을 가질만한 기사나 논문, 상품을 추천하는 시스템도 텍스트 정보 검색의 기술을 활용해 사용자의 선호도를 분석합니다.\n",
        "\n",
        "### 최근 발전:\n",
        "\n",
        "- **딥러닝 기반 검색**: BERT, GPT 같은 딥러닝 모델들이 등장하면서 텍스트 정보 검색에서 문맥을 더 잘 이해하는 시스템이 구축되고 있습니다. 전통적인 TF-IDF나 벡터 공간 모델에서 벗어나, 문서의 의미적 유사성을 파악하는 방법으로 발전하고 있습니다.\n",
        "- **자연어 처리 (NLP)와의 결합**: 텍스트 정보 검색은 자연어 처리(NLP) 기술과 밀접하게 연결되어 있으며, 문서의 내용을 더욱 깊이 이해할 수 있도록 발전하고 있습니다.\n",
        "\n",
        "### Whoosh 라이브러리\n",
        "\n",
        "Whoosh는 Python으로 작성된 경량 텍스트 검색 및 인덱싱 라이브러리로, 빠르고 유연한 풀 텍스트 검색을 가능하게 합니다. Lucene과 유사한 개념을 바탕으로 개발되었으며, 다양한 데이터 검색 및 정보 검색 시스템에 활용될 수 있습니다. 특히, SQL 데이터베이스나 외부 서버와의 연결 없이도 쉽게 사용할 수 있어 작고 독립적인 애플리케이션에서 적합합니다.\n",
        "\n",
        "### 주요 특징:\n",
        "\n",
        "1. **경량성**: Whoosh는 데이터베이스나 외부 의존성이 없어 가볍고, 독립적인 시스템에서 사용 가능합니다.\n",
        "2. **순수 Python 구현**: 순수 Python으로 작성되어 있으며, 설치와 사용이 간편합니다.\n",
        "3. **풀 텍스트 검색**: 텍스트 문서를 인덱싱하고, 검색어에 대한 정확한 결과를 제공합니다. 또한, 쿼리와 매칭된 문서의 랭킹을 지원합니다.\n",
        "4. **다양한 필드 지원**: 텍스트, 숫자, 날짜 등 다양한 필드를 지원하며, 각 필드는 검색과 인덱싱에서 다르게 처리될 수 있습니다.\n",
        "5. **유연한 쿼리 지원**: 복잡한 검색 쿼리도 처리할 수 있으며, AND, OR, NOT 등의 논리 연산자를 사용할 수 있습니다.\n",
        "6. **빠른 검색**: 적은 메모리 자원을 사용하면서도 빠른 검색을 제공합니다. 작은 규모의 프로젝트나 애플리케이션에서 매우 유용합니다.\n",
        "\n",
        "### 주요 구성 요소:\n",
        "\n",
        "1. **Schema (스키마)**: 인덱스에 저장될 데이터의 구조를 정의합니다. 각 필드는 어떤 종류의 데이터를 포함하는지를 결정합니다 (예: 텍스트, 숫자 등).\n",
        "2. **Index (인덱스)**: 검색을 위해 데이터를 저장하고 관리하는 공간입니다. 인덱스는 문서들을 효율적으로 검색할 수 있도록 구조화된 데이터베이스라고 생각할 수 있습니다.\n",
        "3. **Writer (작성기)**: 인덱스에 데이터를 추가하거나 갱신할 때 사용하는 객체입니다. 새로운 문서를 인덱스에 추가하거나, 기존 문서를 삭제할 수 있습니다.\n",
        "4. **Searcher (검색기)**: 인덱스를 검색하는 데 사용됩니다. 쿼리를 사용하여 검색을 수행하고 결과를 반환합니다.\n",
        "5. **QueryParser (쿼리 파서)**: 검색 쿼리를 파싱하여 `Searcher`가 사용할 수 있는 형태로 변환합니다. 사용자가 입력한 검색어를 해석하여 검색 엔진이 처리할 수 있는 쿼리로 변환하는 역할을 합니다."
      ],
      "metadata": {
        "id": "U5gRUslpWdx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예시 1:\n",
        "\n",
        "아래는 Whoosh를 사용해 텍스트 데이터를 인덱싱하고 검색하는 간단한 예시입니다.\n",
        "\n",
        "필요 라이브러리 설치"
      ],
      "metadata": {
        "id": "Z1bMwy6SWhBe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6IGqmwqV_In"
      },
      "outputs": [],
      "source": [
        "!pip install whoosh\n",
        "!pip install openai==0.27.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from whoosh.index import create_in, open_dir  # open_dir 추가\n",
        "from whoosh.fields import Schema, TEXT\n",
        "from whoosh.qparser import QueryParser\n",
        "import os\n",
        "\n",
        "# 스키마 정의 (title과 content로 구성)\n",
        "schema = Schema(title=TEXT(stored=True), content=TEXT(stored=True))\n",
        "\n",
        "# 인덱스 저장할 디렉토리 생성\n",
        "if not os.path.exists(\"indexdir\"):\n",
        "    os.mkdir(\"indexdir\")\n",
        "\n",
        "# 인덱스 생성\n",
        "ix = create_in(\"indexdir\", schema)\n",
        "writer = ix.writer()\n",
        "\n",
        "# 문서 추가 (내용을 복잡하게 작성)\n",
        "writer.add_document(\n",
        "    title=\"Python\",\n",
        "    content=(\n",
        "        \"Python은 1991년 Guido van Rossum이 처음 발표한 범용 프로그래밍 언어입니다. \"\n",
        "        \"이 언어는 코드 가독성을 중시하며, 동적 타이핑, 메모리 관리 기능을 포함한 \"\n",
        "        \"높은 수준의 내장 기능을 제공합니다. 다양한 프로그래밍 패러다임을 지원하며, \"\n",
        "        \"특히 객체 지향, 명령형, 함수형 프로그래밍을 사용할 수 있습니다. \"\n",
        "        \"주요 라이브러리로는 NumPy, pandas, Flask, Django 등이 있으며, \"\n",
        "        \"현재는 데이터 분석, 웹 개발, 인공지능, 머신러닝 등 다양한 분야에서 폭넓게 사용되고 있습니다.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "writer.add_document(\n",
        "    title=\"Whoosh\",\n",
        "    content=(\n",
        "        \"Whoosh는 Python으로 작성된 경량 텍스트 검색 및 인덱싱 라이브러리입니다. \"\n",
        "        \"이 라이브러리는 Lucene과 유사한 기능을 제공하며, 빠르고 유연한 검색을 가능하게 합니다. \"\n",
        "        \"Whoosh는 SQL 데이터베이스나 외부 서버와의 통합이 필요하지 않아, 작고 독립적인 애플리케이션에 적합합니다. \"\n",
        "        \"텍스트 문서를 인덱싱하여 역파일(Inverted Index) 형태로 저장하고, \"\n",
        "        \"이후 사용자의 검색 질의에 따라 적절한 문서를 빠르게 찾아내는 것이 주요 기능입니다. \"\n",
        "        \"Whoosh는 풀 텍스트 검색, 유연한 쿼리 기능, 그리고 스코어링을 통해 검색 결과를 정렬할 수 있습니다.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "writer.add_document(\n",
        "    title=\"GPT\",\n",
        "    content=(\n",
        "        \"GPT(Generative Pre-trained Transformer)는 OpenAI에서 개발한 자연어 처리 모델입니다. \"\n",
        "        \"이 모델은 대규모 텍스트 데이터를 학습하여, 새로운 문장을 생성하거나, \"\n",
        "        \"주어진 질문에 대한 답변을 제공할 수 있습니다. GPT는 트랜스포머(Transformer) \"\n",
        "        \"구조를 기반으로 하며, 특히 다중 헤드 셀프 어텐션(Multi-head Self-attention) 기법을 사용하여 \"\n",
        "        \"효율적으로 문맥을 이해합니다. 최근 발표된 GPT-3와 GPT-4는 1750억 개 이상의 매개변수를 사용해 \"\n",
        "        \"더욱 정교하고 복잡한 언어 모델링을 가능하게 합니다. 이러한 모델은 챗봇, 번역, 요약, 질의 응답 등 \"\n",
        "        \"다양한 자연어 처리 응용에 활용됩니다.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "writer.commit()\n",
        "\n",
        "# 검색\n",
        "def search_whoosh(query_str):\n",
        "    ix = open_dir(\"indexdir\")  # open_dir 사용\n",
        "    with ix.searcher() as searcher:\n",
        "        query = QueryParser(\"content\", ix.schema).parse(query_str)\n",
        "        results = searcher.search(query)\n",
        "        for result in results:\n",
        "            print(f\"Title: {result['title']}\\nContent: {result['content']}\\n\")\n",
        "\n",
        "# 예시 검색 실행\n",
        "search_whoosh(\"트랜스포머\")"
      ],
      "metadata": {
        "id": "yZoWQ54jWjb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예시 2:\n",
        "\n",
        "위키피디아 내용을 실제로 가져와서 인덱싱하고 검색 결과를 출력하려면, 먼저 위키피디아에서 데이터를 가져오는 방법을 구현한 후, 그 데이터를 Whoosh로 인덱싱해야 합니다.\n",
        "\n",
        "위키피디아 데이터를 가져오는 방법에는 여러 가지가 있습니다. 가장 일반적인 방법은 `wikipedia-api` 라이브러리를 사용하는 것입니다. 이 라이브러리는 위키피디아 페이지 내용을 Python에서 쉽게 가져올 수 있도록 돕습니다.\n",
        "\n",
        "아래는 위키피디아에서 문서를 가져와서 Whoosh로 인덱싱하고 검색하는 예제 코드입니다."
      ],
      "metadata": {
        "id": "SkI1wIj1Wlzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. `wikipedia-api` 설치\n",
        "\n",
        "먼저 위키피디아 API를 설치합니다."
      ],
      "metadata": {
        "id": "b7w8leDFWm82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wikipedia-api"
      ],
      "metadata": {
        "id": "bmZnpmeuWnvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 위키피디아 내용을 인덱싱하고 검색하는 코드"
      ],
      "metadata": {
        "id": "ZKXhbs87Wotu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipediaapi\n",
        "from whoosh.index import create_in, open_dir\n",
        "from whoosh.fields import Schema, TEXT\n",
        "from whoosh.qparser import QueryParser\n",
        "import os\n",
        "\n",
        "# 위키피디아 API 설정 (User-Agent를 명시적으로 지정)\n",
        "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
        "wiki_wiki = wikipediaapi.Wikipedia(\n",
        "    language='ko',\n",
        "    user_agent=user_agent  # 한국어 위키피디아 사용, User-Agent 추가\n",
        ")\n",
        "\n",
        "# 위키피디아 문서 가져오기\n",
        "def get_wikipedia_page(title):\n",
        "    page = wiki_wiki.page(title)\n",
        "    if page.exists():\n",
        "        print(f\"Retrieved page for {title}\")  # 디버깅 출력\n",
        "        return page.title, page.text\n",
        "    else:\n",
        "        print(f\"Page for {title} does not exist.\")  # 디버깅 출력\n",
        "        return None, None\n",
        "\n",
        "# 스키마 정의 (title과 content로 구성)\n",
        "schema = Schema(title=TEXT(stored=True), content=TEXT(stored=True))\n",
        "\n",
        "# 인덱스 저장할 디렉토리 생성\n",
        "if not os.path.exists(\"indexdir\"):\n",
        "    os.mkdir(\"indexdir\")\n",
        "\n",
        "# 인덱스 생성\n",
        "ix = create_in(\"indexdir\", schema)\n",
        "writer = ix.writer()\n",
        "\n",
        "# 위키피디아 문서 제목 리스트\n",
        "wiki_titles = [\"라부아지에\", \"뉴튼\", \"데카르트\", \"퓨리에\", \"퀴리\"]\n",
        "\n",
        "# 문서 추가 (위키피디아 문서 가져와서 인덱싱)\n",
        "for title in wiki_titles:\n",
        "    wiki_title, wiki_content = get_wikipedia_page(title)\n",
        "    if wiki_title and wiki_content:\n",
        "        writer.add_document(title=wiki_title, content=wiki_content)\n",
        "        print(f\"Indexed: {wiki_title}\")  # 디버깅 출력\n",
        "\n",
        "writer.commit()\n",
        "\n",
        "# 검색\n",
        "def search_whoosh(query_str):\n",
        "    ix = open_dir(\"indexdir\")\n",
        "    with ix.searcher() as searcher:\n",
        "        # 타이틀 필드와 콘텐츠 필드에 대해 각각 검색\n",
        "        title_parser = QueryParser(\"title\", ix.schema)\n",
        "        content_parser = QueryParser(\"content\", ix.schema)\n",
        "\n",
        "        title_query = title_parser.parse(query_str)\n",
        "        content_query = content_parser.parse(query_str)\n",
        "\n",
        "        title_results = searcher.search(title_query)\n",
        "        content_results = searcher.search(content_query)\n",
        "\n",
        "        if title_results or content_results:\n",
        "            for result in title_results:\n",
        "                print(f\"Title match: {result['title']}\\nContent: {result['content'][:500]}...\\n\")\n",
        "            for result in content_results:\n",
        "                print(f\"Content match: {result['title']}\\nContent: {result['content'][:500]}...\\n\")\n",
        "        else:\n",
        "            print(\"검색 결과가 없습니다.\")\n",
        "\n",
        "# 예시 검색 실행\n",
        "search_whoosh(\"라부아지에\")\n"
      ],
      "metadata": {
        "id": "Imi87DG4WpnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Whoosh가 유용한 경우:\n",
        "\n",
        "- 작은 규모의 애플리케이션에서 텍스트 검색 기능이 필요할 때.\n",
        "- 데이터베이스와 통합하지 않고 검색 기능만 별도로 구현하고 싶을 때.\n",
        "- 복잡한 설정이 필요 없고, 빠르게 검색 기능을 추가하고자 할 때."
      ],
      "metadata": {
        "id": "m9FvQZwRWrhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예시 3\n",
        "\n",
        "Whoosh를 이용해 다양한 스키마 구조를 적용하는 예시입니다."
      ],
      "metadata": {
        "id": "VL91PyoKWs5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from whoosh.index import create_in, open_dir\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, DATETIME, ID\n",
        "from whoosh.qparser import MultifieldParser, QueryParser, WildcardPlugin\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# 1. 스키마 정의 (Schema Definition)\n",
        "# Whoosh에서는 다양한 데이터 필드를 손쉽게 추가할 수 있으며, 추가적인 데이터 변경 시에도 별도의 스키마 마이그레이션이 필요하지 않음\n",
        "schema = Schema(\n",
        "    doc_id=ID(stored=True, unique=True),\n",
        "    title=TEXT(stored=True),\n",
        "    content=TEXT(stored=True),\n",
        "    author=TEXT(stored=True),\n",
        "    tags=KEYWORD(stored=True, commas=True, lowercase=True),\n",
        "    published_date=DATETIME(stored=True)\n",
        ")\n",
        "\n",
        "# 2. 인덱스 저장할 디렉토리 생성\n",
        "index_dir = \"indexdir_flexible\"\n",
        "if not os.path.exists(index_dir):\n",
        "    os.mkdir(index_dir)\n",
        "\n",
        "# 3. 인덱스 생성\n",
        "ix = create_in(index_dir, schema)\n",
        "writer = ix.writer()\n",
        "\n",
        "# 4. 문서 추가 (Ease of Adding Data)\n",
        "# Whoosh에서는 서로 다른 구조의 문서도 문제없이 추가할 수 있어, 다양한 데이터를 유연하게 저장할 수 있음\n",
        "documents = [\n",
        "    {\n",
        "        \"doc_id\": \"1\",\n",
        "        \"title\": \"파이썬 소개\",\n",
        "        \"content\": \"파이썬은 웹 개발, 데이터 분석 등 다양한 분야에서 사용되는 인기 있는 프로그래밍 언어입니다.\",\n",
        "        \"author\": \"홍길동\",\n",
        "        \"tags\": \"파이썬, 프로그래밍, 개발\",\n",
        "        \"published_date\": datetime(2021, 5, 17)\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"2\",\n",
        "        \"title\": \"고급 파이썬 프로그래밍\",\n",
        "        \"content\": \"이 문서는 파이썬 프로그래밍의 고급 주제인 데코레이터, 제너레이터, 메타클래스 등을 다룹니다.\",\n",
        "        \"author\": \"이영희\",\n",
        "        \"tags\": \"파이썬, 고급, 프로그래밍\",\n",
        "        \"published_date\": datetime(2022, 8, 24)\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"3\",\n",
        "        \"title\": \"파이썬을 이용한 데이터 과학\",\n",
        "        \"content\": \"파이썬을 사용하여 데이터 과학을 수행하는 방법을 배우고, Pandas, NumPy 및 데이터 시각화에 대해 알아봅니다.\",\n",
        "        \"author\": \"홍길동\",\n",
        "        \"tags\": \"파이썬, 데이터 과학, 판다스, 넘파이\",\n",
        "        \"published_date\": datetime(2023, 3, 12)\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"4\",\n",
        "        \"title\": \"웹 개발 기초\",\n",
        "        \"content\": \"이 문서는 HTML, CSS, JavaScript를 포함한 웹 개발의 기초를 소개합니다.\",\n",
        "        \"author\": \"이영희\",\n",
        "        \"tags\": \"웹 개발, html, css, 자바스크립트\",\n",
        "        \"published_date\": datetime(2020, 11, 5)\n",
        "    }\n",
        "]\n",
        "\n",
        "for doc in documents:\n",
        "    writer.add_document(\n",
        "        doc_id=doc[\"doc_id\"],\n",
        "        title=doc[\"title\"],\n",
        "        content=doc[\"content\"],\n",
        "        author=doc[\"author\"],\n",
        "        tags=doc[\"tags\"],\n",
        "        published_date=doc[\"published_date\"]\n",
        "    )\n",
        "\n",
        "writer.commit()\n",
        "\n",
        "# 5. 검색 함수 (Convenient Search Options)\n",
        "# 복잡한 SQL 대신 간단한 쿼리 구문으로 다양한 필드를 한번에 검색 가능\n",
        "def search_documents(query_str):\n",
        "    ix = open_dir(index_dir)\n",
        "    with ix.searcher() as searcher:\n",
        "        parser = MultifieldParser([\"title\", \"content\", \"tags\"], schema=ix.schema)\n",
        "        query = parser.parse(query_str)\n",
        "        results = searcher.search(query)\n",
        "        for result in results:\n",
        "            print(f\"제목: {result['title']}, 저자: {result['author']}, 태그: {result['tags']}\")\n",
        "\n",
        "# 6. 예제 검색\n",
        "# 텍스트 기반의 자연스러운 검색이 가능하고, 부분 일치, 와일드카드 등의 편리한 검색 기능 지원\n",
        "print(\"전체 텍스트 검색 예제:\")\n",
        "search_documents(\"파이썬\")\n",
        "\n",
        "print(\"\\\\n특정 키워드와 일치하는 내용 검색:\")\n",
        "search_documents(\"고급 OR 데이터 과학\")\n",
        "\n",
        "print(\"\\\\n태그를 기반으로 한 검색 (Whoosh는 키워드 기반 검색도 지원):\")\n",
        "search_documents(\"파이썬 AND 개발\")\n"
      ],
      "metadata": {
        "id": "0Y6HeBSaWtt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **다양한 데이터 저장**:\n",
        "    - Whoosh는 새로운 필드나 다양한 데이터 유형을 저장할 때 별도의 스키마 변경 작업이 필요 없습니다. RDB에서는 테이블에 새로운 열을 추가하거나 데이터 구조를 변경할 때마다 스키마 마이그레이션이 필요할 수 있습니다.\n",
        "2. **편리한 검색 기능**:\n",
        "    - **텍스트 기반 검색**: Whoosh는 복잡한 SQL 구문 없이도 텍스트를 기반으로 한 다양한 검색 쿼리를 사용할 수 있습니다.\n",
        "    - **자연어 검색 지원**: `MultifieldParser`를 사용해 여러 필드를 동시에 검색하고, `OR`, `AND` 등의 연산자를 통해 유연한 검색이 가능합니다.\n",
        "    - **와일드카드 및 부분 일치**: Whoosh는 기본적으로 와일드카드(``)나 부분 일치를 지원하여 사용자가 원하는 결과를 더욱 쉽게 검색할 수 있습니다.\n",
        "3. **빠른 색인 및 검색 속도**:\n",
        "    - **역색인(inverted index)**: Whoosh는 텍스트 데이터를 역색인 형태로 저장하여, 특정 키워드나 패턴으로 빠르게 검색할 수 있도록 설계되어 있습니다. 이는 특히 큰 텍스트 파일에서 유리합니다.\n",
        "    - **자연스러운 확장성**: 새로운 문서를 추가할 때 관계형 데이터베이스처럼 복잡한 트랜잭션이나 데이터 일관성 문제를 고려할 필요가 적습니다.\n",
        "\n",
        "### Whoosh가 편리한 이유:\n",
        "\n",
        "- **비정형 데이터 처리에 유리**: 텍스트 기반의 비정형 데이터(문서, 이메일, 블로그 게시물 등)를 효과적으로 관리하고 검색할 수 있습니다.\n",
        "- **간단한 설정**: RDB에서는 테이블 간의 관계와 제약 조건을 설정하는 데 시간이 걸리지만, Whoosh는 스키마 설정이 간단하고 유연하여 더 쉽게 시작할 수 있습니다.\n",
        "- **텍스트 검색 특화**: 자연어 검색이나 키워드 검색과 같은 기능이 내장되어 있어 별도의 복잡한 설정 없이 사용할 수 있습니다.\n",
        "\n",
        "Whoosh는 텍스트 기반의 애플리케이션에서 **빠르고 유연한 검색 기능**을 제공하는 반면, RDB는 데이터의 **정확한 일관성**과 **관계 관리**를 보장하는 데 최적화되어 있습니다."
      ],
      "metadata": {
        "id": "dc9E8of8Wwp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예시 4:\n",
        "\n",
        "Whoosh에 의해 검색된 결과에 LLM을 이용해 부드럽게 표현"
      ],
      "metadata": {
        "id": "4bHRDoiVWxoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from whoosh.index import create_in, open_dir\n",
        "from whoosh.fields import Schema, TEXT\n",
        "from whoosh.qparser import QueryParser, WildcardPlugin\n",
        "import os\n",
        "import openai\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "openai.api_key = \"\"\n",
        "\n",
        "# 1. 스키마 정의 (title, content)\n",
        "schema = Schema(title=TEXT(stored=True), content=TEXT(stored=True))\n",
        "\n",
        "# 2. 인덱스 저장할 디렉토리 생성\n",
        "if not os.path.exists(\"indexdir\"):\n",
        "    os.mkdir(\"indexdir\")\n",
        "\n",
        "# 3. 인덱스 생성\n",
        "ix = create_in(\"indexdir\", schema)\n",
        "writer = ix.writer()\n",
        "\n",
        "# 한국어 위키피디아 데이터를 title과 content로 나누어 인덱싱\n",
        "wiki_data = [\n",
        "    {\"title\": \"파이썬\", \"content\": \"파이썬(Python)은 범용 프로그래밍 언어입니다...\"},\n",
        "    {\"title\": \"GPT\", \"content\": \"GPT는 OpenAI에서 개발한 언어 모델로, 자연어 처리에 사용됩니다...\"},\n",
        "    {\"title\": \"대한민국\", \"content\": \"대한민국은 동아시아에 위치한 민주공화국입니다...\"},\n",
        "    # 더 많은 데이터 추가 가능\n",
        "]\n",
        "\n",
        "# 데이터 인덱스에 추가\n",
        "for entry in wiki_data:\n",
        "    writer.add_document(title=entry[\"title\"], content=entry[\"content\"])\n",
        "    print(f\"Indexed: {entry['title']}\")  # 인덱스된 데이터를 확인하는 출력\n",
        "\n",
        "writer.commit()\n",
        "\n",
        "# 4. 검색 기능 구현\n",
        "def search_wikipedia(query):\n",
        "    ix = open_dir(\"indexdir\")\n",
        "    with ix.searcher() as searcher:\n",
        "        parser = QueryParser(\"content\", ix.schema)\n",
        "        parser.add_plugin(WildcardPlugin())  # Wildcard를 허용하는 플러그인 추가\n",
        "        q = parser.parse(f\"{query}*\")  # 부분 일치를 허용하기 위해 Wildcard 쿼리 사용\n",
        "        results = searcher.search(q)\n",
        "        if results:\n",
        "            return [result['content'] for result in results]\n",
        "        else:\n",
        "            return []\n",
        "\n",
        "# 5. GPT-3.5 Turbo로 답변 생성\n",
        "def generate_answer_from_gpt(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# 6. 검색어에서 키워드 추출\n",
        "def extract_keyword(question):\n",
        "    # 가장 간단한 방법으로 키워드를 추출하는 과정. 실제로는 자연어 처리로 개선 가능\n",
        "    keywords = [\"파이썬\", \"GPT\", \"대한민국\"]\n",
        "    for keyword in keywords:\n",
        "        if keyword in question:\n",
        "            return keyword\n",
        "    return None\n",
        "\n",
        "# 7. 검색 결과 기반 GPT-3.5 답변 생성\n",
        "def answer_question_with_wikipedia(question):\n",
        "    keyword = extract_keyword(question)\n",
        "    if not keyword:\n",
        "        return \"질문에서 키워드를 추출할 수 없습니다.\"\n",
        "\n",
        "    search_results = search_wikipedia(keyword)\n",
        "\n",
        "    if not search_results:\n",
        "        return \"위키피디아에서 관련된 정보를 찾을 수 없습니다.\"\n",
        "\n",
        "    # 검색된 결과를 기반으로 GPT-3.5에게 답변 요청\n",
        "    prompt = f\"다음 위키피디아 데이터를 바탕으로 질문에 답해주세요: {search_results[0]}\\n\\n질문: {question}\"\n",
        "    answer = generate_answer_from_gpt(prompt)\n",
        "    return answer\n",
        "\n",
        "# 8. 예시 사용\n",
        "question = \"GPT\"\n",
        "print(answer_question_with_wikipedia(question))"
      ],
      "metadata": {
        "id": "Y83u8zt7Wyz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위키피디아 문서에서 정보를 검색하여 사용자의 질문에 답변하는 시스템을 구축합니다. LLM을 사용해 검색된 정보에 기반한 자연스러운 답변을 생성합니다.\n",
        "\n",
        "Python의 Whoosh 라이브러리를 사용해 위키피디아 데이터에 대한 인덱스를 생성하고, GPT-3를 활용해 검색된 정보를 바탕으로 사용자의 질문에 대한 답변을 작성합니다."
      ],
      "metadata": {
        "id": "VBYyj-FjW0Im"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예시 5:\n",
        "\n",
        "위 코드를 이용해 도로교통법 음주운전을 Whoosh로 검색하고 LLM으로 처리한 예"
      ],
      "metadata": {
        "id": "H22e2_XoW1Hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from whoosh.index import create_in, open_dir\n",
        "from whoosh.fields import Schema, TEXT\n",
        "from whoosh.qparser import QueryParser, WildcardPlugin\n",
        "import os\n",
        "import openai\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "openai.api_key = \"\"\n",
        "\n",
        "# 1. 스키마 정의 (title, content)\n",
        "schema = Schema(title=TEXT(stored=True), content=TEXT(stored=True))\n",
        "\n",
        "# 2. 인덱스 저장할 디렉토리 생성\n",
        "if not os.path.exists(\"indexdir\"):\n",
        "    os.mkdir(\"indexdir\")\n",
        "\n",
        "# 3. 인덱스 생성\n",
        "ix = create_in(\"indexdir\", schema)\n",
        "writer = ix.writer()\n",
        "\n",
        "# 도로교통법 제148조의2 관련 내용 추가\n",
        "wiki_data = [\n",
        "    {\n",
        "        \"title\": \"도로교통법 제148조의2\",\n",
        "        \"content\": \"\"\"\n",
        "        도로교통법 제148조의2(벌칙) ① 제44조제1항 또는 제2항을 위반(자동차등 또는 노면전차를 운전한 경우로 한정한다. 다만, 개인형 이동장치를 운전한 경우는 제외한다. 이하 이 조에서 같다)하여 벌금 이상의 형을 선고받고 그 형이 확정된 날부터 10년 내에 다시 같은 조 제1항 또는 제2항을 위반한 사람(형이 실효된 사람도 포함한다)은 다음 각 호의 구분에 따라 처벌한다. <개정 2023. 1. 3.>\n",
        "1. 제44조제2항을 위반한 사람은 1년 이상 6년 이하의 징역이나 500만원 이상 3천만원 이하의 벌금에 처한다.\n",
        "2. 제44조제1항을 위반한 사람 중 혈중알코올농도가 0.2퍼센트 이상인 사람은 2년 이상 6년 이하의 징역이나 1천만원 이상 3천만원 이하의 벌금에 처한다.\n",
        "3. 제44조제1항을 위반한 사람 중 혈중알코올농도가 0.03퍼센트 이상 0.2퍼센트 미만인 사람은 1년 이상 5년 이하의 징역이나 500만원 이상 2천만원 이하의 벌금에 처한다.\n",
        "② 술에 취한 상태에 있다고 인정할 만한 상당한 이유가 있는 사람으로서 제44조제2항에 따른 경찰공무원의 측정에 응하지 아니하는 사람(자동차등 또는 노면전차를 운전한 경우로 한정한다)은 1년 이상 5년 이하의 징역이나 500만원 이상 2천만원 이하의 벌금에 처한다. <개정 2023. 1. 3.>\n",
        "③ 제44조제1항을 위반하여 술에 취한 상태에서 자동차등 또는 노면전차를 운전한 사람은 다음 각 호의 구분에 따라 처벌한다.\n",
        "1. 혈중알코올농도가 0.2퍼센트 이상인 사람은 2년 이상 5년 이하의 징역이나 1천만원 이상 2천만원 이하의 벌금\n",
        "2. 혈중알코올농도가 0.08퍼센트 이상 0.2퍼센트 미만인 사람은 1년 이상 2년 이하의 징역이나 500만원 이상 1천만원 이하의 벌금\n",
        "3. 혈중알코올농도가 0.03퍼센트 이상 0.08퍼센트 미만인 사람은 1년 이하의 징역이나 500만원 이하의 벌금\n",
        "④ 제45조를 위반하여 약물로 인하여 정상적으로 운전하지 못할 우려가 있는 상태에서 자동차등 또는 노면전차를 운전한 사람은 3년 이하의 징역이나 1천만원 이하의 벌금에 처한다.\n",
        "        \"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# 데이터 인덱스에 추가\n",
        "for entry in wiki_data:\n",
        "    writer.add_document(title=entry[\"title\"], content=entry[\"content\"])\n",
        "    print(f\"Indexed: {entry['title']}\")  # 인덱스된 데이터를 확인하는 출력\n",
        "\n",
        "writer.commit()\n",
        "\n",
        "# 4. 검색 기능 구현\n",
        "def search_wikipedia(query):\n",
        "    ix = open_dir(\"indexdir\")\n",
        "    with ix.searcher() as searcher:\n",
        "        parser = QueryParser(\"content\", ix.schema)\n",
        "        parser.add_plugin(WildcardPlugin())  # Wildcard를 허용하는 플러그인 추가\n",
        "        q = parser.parse(f\"{query}*\")  # 부분 일치를 허용하기 위해 Wildcard 쿼리 사용\n",
        "        results = searcher.search(q)\n",
        "        if results:\n",
        "            return [result['content'] for result in results]\n",
        "        else:\n",
        "            return []\n",
        "\n",
        "# 5. GPT-3.5 Turbo로 답변 생성\n",
        "def generate_answer_from_gpt(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# 6. 검색어에서 키워드 추출\n",
        "def extract_keyword(question):\n",
        "    # 도로교통법이나 처벌 관련 키워드를 포함한 질문을 처리\n",
        "    if \"도로교통법\" in question or \"혈중 알콜농도\" in question or \"처벌\" in question:\n",
        "        return \"도로교통법 제148조의2\"\n",
        "    return None\n",
        "\n",
        "# 7. 검색 결과 기반 GPT-3.5 답변 생성\n",
        "def answer_question_with_wikipedia(question):\n",
        "    keyword = extract_keyword(question)\n",
        "    if not keyword:\n",
        "        return \"질문에서 키워드를 추출할 수 없습니다.\"\n",
        "\n",
        "    search_results = search_wikipedia(keyword)\n",
        "\n",
        "    if not search_results:\n",
        "        return \"도로교통법에서 관련된 정보를 찾을 수 없습니다.\"\n",
        "\n",
        "    # 검색된 결과를 기반으로 GPT-3.5에게 답변 요청\n",
        "    prompt = f\"다음 도로교통법 제148조의2 음주운전 위반 데이터를 바탕으로 질문에 답해주세요: {search_results[0]}\\n\\n질문: {question}\"\n",
        "    answer = generate_answer_from_gpt(prompt)\n",
        "    return answer\n",
        "\n",
        "# 8. 예시 사용\n",
        "question = \"혈중 알콜농도가 0.08인 사람이 받는 처벌은?\"\n",
        "print(answer_question_with_wikipedia(question))\n"
      ],
      "metadata": {
        "id": "7NHMdRrYW13G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예시 6:\n",
        "\n",
        "다음은 도로교통법과 교통사고 법률을 문서화하고 Whoosh로 검색하여 LLM으로 처리한 예 입니다."
      ],
      "metadata": {
        "id": "zKLme7Z2W3b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from whoosh.index import create_in, open_dir\n",
        "from whoosh.fields import Schema, TEXT\n",
        "from whoosh.qparser import QueryParser, WildcardPlugin\n",
        "import os\n",
        "import openai\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "openai.api_key = \"\"\n",
        "\n",
        "# 1. 스키마 정의 (title, content)\n",
        "schema = Schema(title=TEXT(stored=True), content=TEXT(stored=True))\n",
        "\n",
        "# 2. 인덱스 저장할 디렉토리 생성\n",
        "if not os.path.exists(\"indexdir\"):\n",
        "    os.mkdir(\"indexdir\")\n",
        "\n",
        "# 3. 인덱스 생성\n",
        "ix = create_in(\"indexdir\", schema)\n",
        "writer = ix.writer()\n",
        "\n",
        "# 도로교통법 및 교통사고 관련 법률 추가\n",
        "wiki_data = [\n",
        "    {\n",
        "        \"title\": \"도로교통법 제148조의2\",\n",
        "        \"content\": \"\"\"\n",
        "        도로교통법 제148조의2(벌칙) ① 제44조제1항 또는 제2항을 위반(자동차등 또는 노면전차를 운전한 경우로 한정한다. 다만, 개인형 이동장치를 운전한 경우는 제외한다. 이하 이 조에서 같다)하여 벌금 이상의 형을 선고받고 그 형이 확정된 날부터 10년 내에 다시 같은 조 제1항 또는 제2항을 위반한 사람(형이 실효된 사람도 포함한다)은 다음 각 호의 구분에 따라 처벌한다. <개정 2023. 1. 3.>\n",
        "        1. 제44조제2항을 위반한 사람은 1년 이상 6년 이하의 징역이나 500만원 이상 3천만원 이하의 벌금에 처한다.\n",
        "        2. 제44조제1항을 위반한 사람 중 혈중알코올농도가 0.2퍼센트 이상인 사람은 2년 이상 6년 이하의 징역이나 1천만원 이상 3천만원 이하의 벌금에 처한다.\n",
        "        3. 제44조제1항을 위반한 사람 중 혈중알코올농도가 0.03퍼센트 이상 0.2퍼센트 미만인 사람은 1년 이상 5년 이하의 징역이나 500만원 이상 2천만원 이하의 벌금에 처한다.\n",
        "        ② 술에 취한 상태에 있다고 인정할 만한 상당한 이유가 있는 사람으로서 제44조제2항에 따른 경찰공무원의 측정에 응하지 아니하는 사람(자동차등 또는 노면전차를 운전한 경우로 한정한다)은 1년 이상 5년 이하의 징역이나 500만원 이상 2천만원 이하의 벌금에 처한다. <개정 2023. 1. 3.>\n",
        "        ③ 제44조제1항을 위반하여 술에 취한 상태에서 자동차등 또는 노면전차를 운전한 사람은 다음 각 호의 구분에 따라 처벌한다.\n",
        "        1. 혈중알코올농도가 0.2퍼센트 이상인 사람은 2년 이상 5년 이하의 징역이나 1천만원 이상 2천만원 이하의 벌금\n",
        "        2. 혈중알코올농도가 0.08퍼센트 이상 0.2퍼센트 미만인 사람은 1년 이상 2년 이하의 징역이나 500만원 이상 1천만원 이하의 벌금\n",
        "        3. 혈중알코올농도가 0.03퍼센트 이상 0.08퍼센트 미만인 사람은 1년 이하의 징역이나 500만원 이하의 벌금\n",
        "        ④ 제45조를 위반하여 약물로 인하여 정상적으로 운전하지 못할 우려가 있는 상태에서 자동차등 또는 노면전차를 운전한 사람은 3년 이하의 징역이나 1천만원 이하의 벌금에 처한다.\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"교통사고\",\n",
        "        \"content\": \"\"\"\n",
        "        도로교통법 제140조의2(새로운 조항): 이 조항은 특정 조건 하에서 발생하는 교통사고에 대한 규제를 명시하고 있으며, 교통사고의 중대성에 따라 차등 처벌을 규정합니다.\n",
        "        주요 내용:\n",
        "        1. 중대한 교통사고로 사상자가 발생한 경우, 사고 가해자는 3년 이상의 징역형에 처할 수 있습니다.\n",
        "        2. 피해자의 중상해가 인정되는 경우, 1년 이상의 징역형 또는 벌금형에 처해질 수 있습니다.\n",
        "        3. 가벼운 사고로 인한 벌금형 및 면허 정지 조치.\n",
        "        앞차와 추돌하여 중상해가 발생.\n",
        "        차량이 전복하여 중상해가 발생.\n",
        "        \"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# 데이터 인덱스에 추가\n",
        "for entry in wiki_data:\n",
        "    writer.add_document(title=entry[\"title\"], content=entry[\"content\"])\n",
        "    print(f\"Indexed: {entry['title']}\")\n",
        "\n",
        "writer.commit()\n",
        "\n",
        "# BAC 계산 함수\n",
        "def calculate_bac_by_shots(shots, weight_kg, gender, appetizer, hours_passed=0):\n",
        "    alcohol_oz_per_shot = 0.34\n",
        "    total_alcohol_oz = shots * alcohol_oz_per_shot\n",
        "    absorption_modifier = 0.9 if appetizer else 1.0\n",
        "    bac = (total_alcohol_oz * 5.14) / (weight_kg * 2.20462 * (0.73 if gender == 'male' else 0.66)) * absorption_modifier - 0.015 * hours_passed\n",
        "    return round(bac, 4)\n",
        "\n",
        "# 검색 기능 구현\n",
        "def search_law(query):\n",
        "    ix = open_dir(\"indexdir\")\n",
        "    with ix.searcher() as searcher:\n",
        "        parser = QueryParser(\"content\", ix.schema)\n",
        "        parser.add_plugin(WildcardPlugin())\n",
        "        q = parser.parse(f\"{query}*\")\n",
        "        results = searcher.search(q)\n",
        "        return [result['content'] for result in results] if results else []\n",
        "\n",
        "# GPT-3.5 Turbo로 답변 생성\n",
        "def generate_answer_from_gpt(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# 질문 자동 분류 및 답변 생성\n",
        "def answer_question_with_user_input():\n",
        "    try:\n",
        "        # 질문 유형 먼저 선택\n",
        "        question_type = input(\"질문 유형을 선택해주세요 (음주운전/교통사고): \").strip().lower()\n",
        "\n",
        "        # 관련 정보 입력\n",
        "        if question_type == \"음주운전\":\n",
        "            name = input(\"사용자의 이름을 입력해주세요: \")\n",
        "            shots = int(input(\"소주를 몇 잔 마셨습니까? \"))\n",
        "            weight_kg = float(input(\"체중을 입력해주세요 (kg): \"))\n",
        "            gender_input = input(\"성별을 입력해주세요 (남성/여성): \")\n",
        "            appetizer = input(\"어떤 안주를 드셨나요? (없으면 '없음'으로 입력): \")\n",
        "            gender = 'male' if gender_input == \"남성\" else 'female' if gender_input == \"여성\" else None\n",
        "\n",
        "            if gender is None:\n",
        "                return \"올바른 성별을 입력해주세요 ('남성' 또는 '여성').\"\n",
        "\n",
        "            # 안주 유무 확인\n",
        "            has_appetizer = appetizer.lower() != '없음'\n",
        "\n",
        "            # 혈중알콜농도 계산\n",
        "            bac = calculate_bac_by_shots(shots, weight_kg, gender, has_appetizer)\n",
        "            keyword = \"도로교통법 제148조의2\"\n",
        "            search_results = search_law(keyword)\n",
        "\n",
        "            if not search_results:\n",
        "                return \"관련된 법률 정보를 찾을 수 없습니다.\"\n",
        "\n",
        "            bac_info = f\"{name}님, 계산된 혈중알코올농도 (BAC)는 {bac}% 입니다.\\n\"\n",
        "            appetizer_info = f\"소주 {shots}잔과 함께 '{appetizer}'를 드셨군요.\\n\"\n",
        "            dictionary_info = search_results[0]  # Get the dictionary info first\n",
        "            prompt = f\"{dictionary_info}\\n\\n{bac_info}{appetizer_info}위 내용을 참고하여 질문에 답변해 주세요.\"\n",
        "            return generate_answer_from_gpt(prompt)\n",
        "\n",
        "        elif question_type == \"교통사고\":\n",
        "            incident_details = input(\"교통사고 상황을 간단히 설명해주세요: \")\n",
        "            keyword = \"교통사고\"\n",
        "            search_results = search_law(keyword)\n",
        "\n",
        "            if not search_results:\n",
        "                return \"관련된 법률 정보를Here's the continuation and completion of the entire code that you requested:\"\n",
        "\n",
        "            prompt = f\"다음 교통사고처리특례법을 참고하여 아래 상황에 대한 법률적인 설명을 제공해주세요: {search_results[0]}\\n\\n사고 상황: {incident_details}\"\n",
        "            return generate_answer_from_gpt(prompt)\n",
        "\n",
        "        else:\n",
        "            return \"올바른 질문 유형을 선택해주세요 ('음주운전' 또는 '교통사고').\"\n",
        "\n",
        "    except ValueError:\n",
        "        return \"입력한 값이 올바르지 않습니다. 소주 잔수와 체중을 숫자로 입력해주세요.\"\n",
        "\n",
        "# 예시 사용\n",
        "print(answer_question_with_user_input())"
      ],
      "metadata": {
        "id": "nvA0EPnEW4LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 연습문제  1\n",
        "\n",
        "인터넷을 검색해서 특정 기업의 사규를 검색하고 위 코드를 이용해 사규 질의응답 시스템을 개발하시오."
      ],
      "metadata": {
        "id": "czfSGZ8UW_w-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 연습문제  2\n",
        "\n",
        "**문제 1**: Whoosh 라이브러리는 LLM과 함께 어떤 역할을 하나요?\n",
        "\n",
        "- a) 자연어 처리 모델의 출력을 전처리하는 역할\n",
        "- b) 대규모 데이터를 기반으로 질문에 대한 답변을 생성하는 역할\n",
        "- c) 문서나 텍스트 데이터를 인덱싱하고 검색 결과를 반환하는 역할\n",
        "- d) 모델을 훈련시키기 위한 데이터셋을 제공하는 역할\n",
        "\n",
        "**문제 2**: 사용자가 특정 질문을 했을 때, Whoosh와 LLM의 협력 과정에서 어떤 순서로 처리가 이루어지나요?\n",
        "\n",
        "1. 사용자의 질문을 분석하여 관련된 키워드를 추출합니다.\n",
        "2. Whoosh가 해당 키워드로 인덱스에서 관련 데이터를 검색합니다.\n",
        "3. 검색된 데이터를 바탕으로 LLM이 질문에 대한 자연어 답변을 생성합니다.\n",
        "\n",
        "이 과정에서 **가장 먼저** 일어나는 단계는 무엇인가요?\n",
        "\n",
        "- a) LLM이 답변을 생성하는 단계\n",
        "- b) 질문에서 관련 키워드를 추출하는 단계\n",
        "- c) Whoosh가 데이터를 검색하는 단계\n",
        "- d) 검색 결과를 저장하는 단계\n",
        "\n",
        "**문제 3**: LLM과 Whoosh의 결합을 통해 사용자가 얻을 수 있는 이점은 무엇인가요?\n",
        "\n",
        "- a) LLM이 스스로 데이터를 크롤링하고 분석할 수 있다.\n",
        "- b) Whoosh가 실시간 데이터를 제공하여 최신 정보를 검색한다.\n",
        "- c) LLM이 사전에 인덱싱된 데이터를 바탕으로 구체적이고 맞춤형 답변을 제공할 수 있다.\n",
        "- d) Whoosh는 머신러닝 모델을 훈련하는 데 사용된다.\n",
        "\n",
        "**문제 4**: Whoosh에서 특정 질문에 대한 검색 결과가 없을 경우 LLM이 어떤 방식으로 답변을 생성할 수 있나요?\n",
        "\n",
        "- a) LLM은 검색 결과가 없으면 답변을 생성하지 못한다.\n",
        "- b) LLM은 검색 결과가 없을 경우 기본값으로 미리 설정된 답변을 생성한다.\n",
        "- c) LLM은 검색 결과가 없을 경우, 질문만을 바탕으로 자체적인 언어 모델에 따라 답변을 생성할 수 있다.\n",
        "- d) LLM은 Whoosh의 검색 결과 없이 자동으로 외부 API를 호출해 답변을 생성한다.\n",
        "\n",
        "**문제 5**: LLM과 Whoosh를 함께 사용할 때, Whoosh가 LLM과 상호작용하는 방식에서 **가장 중요한** 것은 무엇인가요?\n",
        "\n",
        "- a) 검색된 데이터를 LLM에게 제공하여 답변을 생성하는 데 도움이 되는 정보를 제공하는 것\n",
        "- b) LLM이 Whoosh 인덱스를 업데이트할 수 있도록 하는 것\n",
        "- c) LLM이 검색 결과를 사용하여 데이터를 구조화하는 것\n",
        "- d) Whoosh가 LLM에게 데이터를 제공한 후, LLM이 검색 결과를 다시 인덱싱하는 것"
      ],
      "metadata": {
        "id": "8G0i2h_WXBgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 연습문제  3\n",
        "\n",
        "다음은 **Whoosh**와 **LLM**(GPT-3.5 Turbo) 기반 시스템을 구현하는 데 중점을 둔 코딩 문제입니다. 이 문제들은 텍스트 인덱싱, 검색, 그리고 LLM을 활용한 응답 생성과 관련된 기능을 테스트합니다.\n",
        "\n",
        "코딩 문제 1: **Whoosh를 이용한 텍스트 인덱싱 시스템 구축**\n",
        "\n",
        "**문제**: 주어진 텍스트 데이터를 기반으로 Whoosh 라이브러리를 사용해 간단한 인덱싱 시스템을 구축하세요. 텍스트 데이터는 여러 개의 문서로 구성되며, 각 문서는 제목과 내용으로 이루어져 있습니다. 이 시스템은 나중에 키워드를 기반으로 검색할 수 있어야 합니다.\n",
        "\n",
        "**입력**:"
      ],
      "metadata": {
        "id": "7lhiLLoJXC5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    {\"title\": \"Python Programming\", \"content\": \"Python is a versatile programming language...\"},\n",
        "    {\"title\": \"Artificial Intelligence\", \"content\": \"AI is a field of study focused on...\"},\n",
        "    {\"title\": \"Data Science\", \"content\": \"Data science involves analyzing large datasets...\"}\n",
        "]"
      ],
      "metadata": {
        "id": "zNpWYJEBXDkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**요구 사항**:\n",
        "\n",
        "- Whoosh 라이브러리를 사용하여 인덱스를 생성하고, 각 문서의 제목과 내용을 저장하는 코드를 작성하세요.\n",
        "- 인덱싱한 데이터를 나중에 검색할 수 있도록 구현하세요.\n",
        "\n",
        "**힌트**:\n",
        "\n",
        "- Whoosh의 `Schema`, `create_in`, `add_document`, `open_dir` 등을 사용할 수 있습니다.\n",
        "\n",
        "---\n",
        "\n",
        "코딩 문제 2: **Whoosh 기반 검색 시스템에 LLM 응답 생성 기능 추가**\n",
        "\n",
        "**문제**: 앞서 구축한 Whoosh 인덱싱 시스템을 사용하여 사용자가 키워드를 입력하면 검색된 문서의 내용을 기반으로 GPT-3.5를 사용해 자연어 응답을 생성하는 기능을 추가하세요.\n",
        "\n",
        "**입력**:"
      ],
      "metadata": {
        "id": "uAWsfk9OXFdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자가 입력한 키워드\n",
        "query = \"Python\"\n",
        "\n",
        "# GPT-3.5 Turbo API를 사용해 응답을 생성하는 함수\n",
        "def generate_answer_from_gpt(prompt):\n",
        "    # GPT-3.5 호출 (API 키 필요)\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n"
      ],
      "metadata": {
        "id": "lCUfjuJLXGZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**요구 사항**:\n",
        "\n",
        "- 키워드 기반으로 Whoosh 인덱스에서 관련 문서를 검색하세요.\n",
        "- 검색된 문서 내용을 GPT-3.5에게 전달하고, 자연어로 된 응답을 생성하세요.\n",
        "\n",
        "**힌트**:\n",
        "\n",
        "- Whoosh에서 `QueryParser`를 사용해 인덱스된 데이터를 검색하세요.\n",
        "- GPT-3.5를 호출할 때는 검색된 문서 내용을 바탕으로 적절한 `prompt`를 생성하세요.\n",
        "\n",
        "---\n",
        "\n",
        "코딩 문제 3: **검색 결과가 없을 때 기본 응답 생성하기**\n",
        "\n",
        "**문제**: Whoosh 기반 검색 시스템에서 사용자가 입력한 키워드에 대한 검색 결과가 없을 경우, GPT-3.5를 사용해 기본 응답(\"검색된 결과가 없습니다.\")을 생성하도록 시스템을 수정하세요.\n",
        "\n",
        "**입력**:"
      ],
      "metadata": {
        "id": "sLZSx1dGXHvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 입력\n",
        "query = \"Machine Learning\"\n",
        "\n",
        "# 기본 응답을 생성하는 GPT-3.5 함수\n",
        "def generate_default_answer():\n",
        "    prompt = \"There were no search results found. Can you provide a helpful response based on the lack of information?\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "7D-nFLwSXIkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**요구 사항**:\n",
        "\n",
        "- Whoosh로 검색한 결과가 없을 때, 위의 `generate_default_answer` 함수를 호출하여 기본 응답을 생성하세요.\n",
        "- 검색된 결과가 있을 경우, 기존의 검색된 데이터를 기반으로 LLM을 호출해 답변을 생성하세요.\n",
        "\n",
        "**힌트**:\n",
        "\n",
        "- 검색 결과가 없으면 `len(results) == 0`을 확인하여 `generate_default_answer`를 호출하세요."
      ],
      "metadata": {
        "id": "zneKmx92XJ3d"
      }
    }
  ]
}